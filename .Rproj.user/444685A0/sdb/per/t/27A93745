{
    "contents" : "---\ntitle: \"Применение метода PCA для построения предсказательной модели\"\nauthor: \"Морозов Глеб\"\ndate: \"24 августа 2015 г.\"\noutput: \n  html_document: \n    keep_md: yes\n---\n\nВ данной работе показано применения PCA (метода главных компонент) с целью уменьшения размерности данных на примере данных представленных в рамках соревнования [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer) проводимого на сайте [Kaggle](https://www.kaggle.com). В качестве инструмента проведения исследования используется язык R.\n\n### Вступление\nДанная работа является естественным продолжением [исследования](https://github.com/MorozovG/Kaggle_Digit_Recognizer/blob/master/Digit_Recognizer.md), изучающего зависимость качества модели от размера выборки. В ней для была показана возможность уменьшения количества используемых объектов в обучающей выборке с целью получения приемлимых результатов в условиях ограниченных вычислительных ресурсов. Но, кроме количества объектов, на размер данных влияет и количество используемых признаков. Рассмотрим эту возможность на тех же данных. Используемые данные были подробно изучены в предыдущей работе, поэтому просто загрузим тренировочную выборку в R. \n\n```{r global_options, include=FALSE}\nknitr::opts_chunk$set(warning=FALSE, message=FALSE, cache=T)\n```\n\n```{r results=\"hide\"}\nlibrary(readr)\nlibrary(caret)\nlibrary(ggbiplot)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(rgl)\n```\n\n```{r cache=T}\ndata_train <- read_csv(\"train.csv\")\n```\n\nКак мы уже знаем данные имеют 42000 объектов и 784 признака, представляющие собой значение яркости каждого из пикселей составляющего изображение цифры. Разобъём выборку на тренировочную и тестовую в соотношении 60/40.\n\n```{r cache=T}\nset.seed(111)\nsplit <- createDataPartition(data_train$label, p = 0.6, list = FALSE)\ntrain <- slice(data_train, split)\ntest <- slice(data_train, -split)\n```\n\nТеперь удалим признаки, имеющие константное значение.\n\n```{r cache=T}\nzero_var_col <- nearZeroVar(train, saveMetrics = T)\ntrain <- train[, !zero_var_col$nzv]\ntest <- test[, !zero_var_col$nzv]\ndim(train)\n```\n\nВ итоге осталось 253 признака.\n\n### Теория\n\nМетод главных компонент (PCA) преобразует базовые признаки в новые, каждый из которых является линейной комбинацией изначальных таким образом, что разброс данных (то есть среднеквадратичное отклонение от среднего значения) вдоль них максимален. Метод применяется для визуализации данных и для уменьшения размерности данных (сжатия).\n\n### PCA\n\nДля большей наглядности случайным образом отберём из тренировочной выборки 1000 объектов и изобразим их в пространстве первых двух признаков.\n\n```{r cache=T}\ntrain_1000 <- train[sample(nrow(train), size = 1000),]\nggplot(data = train_1000, aes(x = pixel152, y = pixel153, color = factor(label))) + geom_point()\n```\n\nОчевидно, что объекты перемешаны и выделить среди них группы объектов принадлежащих одному классу проблематично. Проведём преобразование данных по методу главных компонент и изобразим в пространстве первых двух компонент. Замечу, что компоненты расположены в убывающем порядке в зависимости от разброса данных, который приходится вдоль них.\n\n```{r cache=T}\npc <- princomp(train_1000[, -1], cor=TRUE, scores=TRUE)\nggbiplot(pc, obs.scale = 1, var.scale = 1, groups = factor(train_1000$label),\n         ellipse = TRUE, circle = F, var.axes = F) + \n        scale_color_discrete(name = '') + \n        theme(legend.direction = 'horizontal', legend.position = 'top')\n```\n\nОчевидно, что даже в пространстве всего лишь двух признаков уже можно выделить явные группы объектов. Теперь рассмотрим те же данные, но уже в пространстве первых трёх компонент. (Трёхмерное изображение можно вращать и приближать)\n\n```{r setup, include=FALSE}\nlibrary(knitr)\nknit_hooks$set(webgl = hook_webgl)\n```\n\n```{r, webgl=TRUE}\nplot3d(pc$scores[,1:3], col= train_1000$label + 1, size = 0.7, type = \"s\")\n```\n\nВыделение различных классов ещё больше упростилось. Теперь выберем количество компонент, которое будем использовать для дальнейшей работы. Для этого посмотрим на соотношение дисперсии и количество компонент объясняющие её, но уже используя всю тренировочную выборку.\n\n```{r cache=T}\npc <- princomp(train[, -1], cor=TRUE, scores=TRUE)\nvariance <- pc$sdev^2/sum(pc$sdev^2)\ncumvar <- cumsum(variance)\ncumvar <- data.frame(PC = 1:252, CumVar = cumvar)\nggplot(data = cumvar, aes(x = PC, y = CumVar)) + geom_point()\nvariance <- data.frame(PC = 1:252, Var = variance*100)\nggplot(data = variance[1:10,], aes(x = factor(PC), y = Var)) + geom_bar(stat = \"identity\")\nsum(variance$Var[1:70])\n```\n\nДля того, чтобы сохранить более 90 процентов информации, содержащейся в данных достаточно всего лишь 70 компонент, т.е. мы от 784 признаков пришли к 70 и, при этом, потеряли менее 10 процентов вариации данных!\n\nПреобразуем тренировочную и тестовую выборки в пространство главных компонент.\n\n```{r cache=T}\ntrain <- predict(pc) %>% cbind(train$label, .) %>% as.data.frame(.) %>% select(1:71)\ncolnames(train)[1]<- \"label\"\ntrain$label <- as.factor(train$label)\ntest %<>% predict(pc, .) %>% cbind(test$label, .) %>% as.data.frame(.) %>% select(1:71)\ncolnames(test)[1]<- \"label\"\n```\n\nДля выбора параметров моделей я использую пакет `caret`, предоставляющий возможность выполнять параллельные вычисления, используя многоядерность современных процессоров. Поэтому, для ускорения вычислений, я подключу второе ядро процессора своего компьютера.\n\n```{r}\nlibrary(\"doParallel\")\ncl <- makePSOCKcluster(2)\nregisterDoParallel(cl)\n```\n\n### KNN\n\nТеперь приступим к созданию предсказывающих моделей используя преобразованные данные. Создадим первую модель используя метод k ближайших соседей (KNN). В этой модели есть только один параметр - количество ближайших объектов, используемых для классификации объекта. Подбирать этот параметр будем с помощью десятикратной кросс-проверки (10-fold cross-validation (CV)) с разбиением выборки на 10 частей. Оценка производится на случайно отобранной части изначальных объектов. Для оценки качества моделей будем использовать статистику `Accuracy`, представляющий собой процент точно предсказанных классов объектов.\n\n```{r}\nset.seed(111)\ntrain_1000 <- train[sample(nrow(train), size = 1000),]\nctrl <- trainControl(method=\"repeatedcv\",repeats = 3)\n```\n\nДля начала определим область поиска значений параметра.\n\n```{r cache=T}\nknnFit <- train(label ~ ., data = train_1000, method = \"knn\", trControl = ctrl,tuneLength = 20)\nknnFit\n```\n\nТеперь сократим её и получим точное значение.\n\n```{r cache=T}\ngrid <- expand.grid(k=2:5)\nknnFit <- train(label ~ ., data = train_1000, method = \"knn\", trControl = ctrl, tuneGrid=grid)\nknnFit\n```\n\nНаилучший показатель модель имеет при значении параметра k равному 3. Используя это значение получим предсказание на тестовых данных. Построим `Confusion Table` и вычислим `Accuracy`.\n\n```{r cache=T}\nlibrary(class)\nprediction_knn <- knn(train, test, train$label, k=3)\ntable(test$label, prediction_knn)\nsum(diag(table(test$label, prediction_knn)))/nrow(test)\n```\n\n### Random Forest\n\nВторая модель - это Random Forest. У этой модели будем выбирать параметр `mtry` - количество используемых признаков при получении каждого из используемых в ансамбле деревьев. Для выбора наилучшего значения данного параметра пойдём тем же путём, что и ранее.\n\n```{r cache=T}\nrfFit <- train(label ~ ., data = train_1000, method = \"rf\", trControl = ctrl,tuneLength = 3)\nrfFit\n```\n\n```{r cache=T}\ngrid <- expand.grid(mtry=2:6)\nrfFit <- train(label ~ ., data = train_1000, method = \"rf\", trControl = ctrl,tuneGrid=grid)\nrfFit\n```\n\nВыбираем `mtry` равным 4 и получаем `Accuracy` на тестовых данных. Замечу, что пришлось обучать модель на части от доступных тренировочных данных, т.к. для использования всех данных требуется больше оперативной памяти. Но, как показано в предыдущей работе, это не сильно повлияет на конечный результат.\n\n```{r cache=T}\nlibrary(randomForest)\nrfFit <- randomForest(label ~ ., data = train[sample(nrow(train), size = 15000),], mtry = 4)\nprediction_rf<-predict(rfFit,test)\ntable(test$label, prediction_rf)\nsum(diag(table(test$label, prediction_rf)))/nrow(test)\n```\n\n### SVM\n\nИ, наконец, Support Vector Machine. В этой модели будет использоваться `Radial Kernel` и подбираются уже два параметра: `sigma` (регуляризационный параметр) и `C` (параметр, определяющий форму ядра).\n\n```{r cache=T}\nsvmFit <- train(label ~ ., data = train_1000, method = \"svmRadial\", trControl = ctrl,tuneLength = 5)\nsvmFit\n```\n\n```{r cache=T}\ngrid <- expand.grid(C = 4:6, sigma = seq(0.006, 0.009, 0.001))\nsvmFit <- train(label ~ ., data = train_1000, method = \"svmRadial\", trControl = ctrl,tuneGrid=grid)\nsvmFit\n```\n\n```{r cache=T}\nlibrary(kernlab)\nsvmFit <- ksvm(label ~ ., data = train,type=\"C-svc\",kernel=\"rbfdot\",kpar=list(sigma=0.008),C=4)\nprediction_svm <- predict(svmFit, newdata = test)\ntable(test$label, prediction_svm)\nsum(diag(table(test$label, prediction_svm)))/nrow(test)\n```\n\n### Ансамбль моделей\n\nСоздадим четвёртую модель, которая представляет собой ансамбль из трёх моделей, созданных ранее. Эта модель предсказывает то значение, за которое \"голосует\" большинство из использованных моделей.\n\n```{r cache=T}\nall_prediction <- cbind(as.numeric(levels(prediction_knn))[prediction_knn], \n                as.numeric(levels(prediction_rf))[prediction_rf], \n                as.numeric(levels(prediction_svm))[prediction_svm])\n\npredictions_ensemble <- apply(all_prediction, 1, function(row) {\n        row %>% table(.) %>% which.max(.) %>% names(.) %>% as.numeric(.)\n        })\ntable(test$label, predictions_ensemble)\nsum(diag(table(test$label, predictions_ensemble)))/nrow(test)\n```\n\n### Итоги\n\nНа тестовой выборке получены следующие результаты:\n\n|Model|Test Accuracy|\n|:-----:|:--------:|\n|KNN    |0.981   |\n|Random Forest|0.948|\n|SVM|0.971|\n|Ensemble|0.974|\n\nЛучший показатель `Accuracy` имеет модель использующая метод k ближайших соседей (KNN). \n\nОценка моделей на сайте Kaggle приведена в следующей таблице.\n\n|Model|Kaggle Accuracy|\n|:-----:|:--------:|\n|KNN    |0.97171   |\n|Random Forest|0.93286|\n|SVM|0.97786|\n|Ensemble|0.97471|\n\nИ лучшие результаты здесь у SVM.\n\n### Eigenfaces\n\nНу и напоследок, уже из чистого любопытства, посмотрим наглядно на произведённые методом главных компонент преобразования. Для этого, во-первых получим изображение цифр в первоначальном виде.\n\n```{r cache=T}\nset.seed(100)\ntrain_1000 <- data_train[sample(nrow(data_train), size = 1000),]\ncolors<-c('white','black')\ncus_col<-colorRampPalette(colors=colors)\ndefault_par <- par()\nnumber_row <- 28\nnumber_col <- 28\npar(mfrow=c(5,5),pty='s',mar=c(1,1,1,1),xaxt='n',yaxt='n')\nfor(i in 1:25)\n{\n        z<-array(as.matrix(train_1000)[i,-1],dim=c(number_row,number_col))\n        z<-z[,number_col:1]\n        image(1:number_row,1:number_col,z,main=train_1000[i,1],col=cus_col(256))\n}\npar(default_par)\n\n```\n\nИ изображение этих же цифр, но уже после того, как мы использовали метод PCA и оставили первые 70 компонент. Получившиеся объекты принято называть eigenfaces\n\n```{r cache=T}\nzero_var_col <- nearZeroVar(train_1000, saveMetrics = T)\ntrain_1000_cut <- train_1000[, !zero_var_col$nzv]\npca <- prcomp(train_1000_cut[, -1], center = TRUE, scale = TRUE)\nrestr <- pca$x[,1:70] %*% t(pca$rotation[,1:70])\nrestr <- scale(restr, center = FALSE , scale=1/pca$scale)\nrestr <- scale(restr, center = -1 * pca$center, scale=FALSE)\nrestr <- as.data.frame(cbind(train_1000_cut$label, restr))\ntest <- data.frame(matrix(NA, nrow = 1000, ncol = ncol(train_1000)))\nzero_col_number <- 1\nfor (i in 1:ncol(train_1000)) {\n        if (zero_var_col$nzv[i] == F) {\n                test[, i] <- restr[, zero_col_number]\n                zero_col_number <- zero_col_number + 1\n        }\n        else test[, i] <- train_1000[, i]\n}\npar(mfrow=c(5,5),pty='s',mar=c(1,1,1,1),xaxt='n',yaxt='n')\nfor(i in 1:25)\n{\n        z<-array(as.matrix(test)[i,-1],dim=c(number_row,number_col))\n        z<-z[,number_col:1]\n        image(1:number_row,1:number_col,z,main=test[i,1],col=cus_col(256))\n}\npar(default_par)\n\n```\n\n\n\n",
    "created" : 1441197938450.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3216584727",
    "id" : "27A93745",
    "lastKnownWriteTime" : 1441219016,
    "path" : "G:/R lang/Kaggle_Digit_Recognizer/Digit_Recognizer_pca.Rmd",
    "project_path" : "Digit_Recognizer_pca.Rmd",
    "properties" : {
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "type" : "r_markdown"
}